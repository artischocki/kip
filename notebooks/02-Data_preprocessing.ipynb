{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preparation\n",
    "Before starting to train the model, some steps need to be done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1. ROI Extraction\n",
    "The images are large in size (above 2000 x 2000 pixels), so it is better to extract the area that is important to us by using a cropping function. This cropping process should be applied to both the image and the respective masks.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Images/image-11.png\" alt=\"Alt text\" style=\"display: block; margin: 0 auto;\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TASK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "# Input and output directories\n",
    "raw_imgs = Path(\"../images/raw_images\").glob(\"*.jpg\")\n",
    "raw_labels = Path(\"../images/raw_labels\").glob(\"*.png\")\n",
    "cropped_img_dir = Path(\"../images/\") / \"cropped_images\"\n",
    "cropped_label_dir = Path(\"../images/\") / \"cropped_labels\"\n",
    "cropped_img_dir.mkdir(exist_ok=True)\n",
    "cropped_label_dir.mkdir(exist_ok=True)\n",
    "\n",
    "def crop_imgs(input_imgs, output_dir) -> None:\n",
    "   for img_path in input_imgs:\n",
    "      #crop the center section ~> 1400W * 1840H\n",
    "      with Image.open(img_path) as img:\n",
    "         width, height = img.size\n",
    "         left = (width - 1400) // 2\n",
    "         top = (height - 1840) // 2\n",
    "         right = left + 1400\n",
    "         bottom = top + 1840\n",
    "         cropped = img.crop((left, top, right, bottom))\n",
    "         cropped.save(output_dir / img_path.name)\n",
    "   return\n",
    "   \n",
    "crop_imgs(raw_imgs, cropped_img_dir)\n",
    "crop_imgs(raw_labels, cropped_label_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2. Image Format Converting \n",
    "It is recommended to convert the format of both the image and mask to TIFF format, which is suitable for the recommended Convolutional Neural Network (CNN) model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TASK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code\n",
    "##ConTif\n",
    "cropped_imgs = Path(\"../images/cropped_images\").glob(\"*.jpg\")\n",
    "cropped_labels = Path(\"../images/cropped_labels\").glob(\"*.png\")\n",
    "tif_img_dir = Path(\"../images/\") / \"tif_images\"\n",
    "tif_label_dir = Path(\"../images/\") / \"tif_labels\"\n",
    "tif_img_dir.mkdir(exist_ok=True)\n",
    "tif_label_dir.mkdir(exist_ok=True)\n",
    "\n",
    "def convert_imgs_to_tif(input_imgs, output_dir) -> None:\n",
    "    for img_path in input_imgs:\n",
    "        # Convert it to Tif\n",
    "        with Image.open(img_path) as img:\n",
    "            tif_name = img_path.stem + \".tif\"\n",
    "            img.save(output_dir / tif_name, format=\"TIFF\")\n",
    "    return\n",
    "\n",
    "convert_imgs_to_tif(cropped_imgs, tif_img_dir)\n",
    "convert_imgs_to_tif(cropped_labels, tif_label_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3. Image Augmentation\n",
    "\n",
    "After extracting the ROI and converting the image and mask to TIFF format, we need to increase our dataset size using augmentation techniques. Here's how you can implement this method, ensuring that the image name and the respective mask name are the same:\n",
    "\n",
    "* Define Augmentation Parameters: Determine the augmentation techniques to apply, such as rotation, flipping, scaling, etc.\n",
    "\n",
    "* Loop Through Images: Iterate through each image and its corresponding mask.\n",
    "\n",
    "* Apply Augmentation: Apply the defined augmentation techniques to both the image and its mask.\n",
    "\n",
    "* Save Augmented Images: Save the augmented images and their masks with the same names as the original images and masks.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Images/image-12.png\" alt=\"Alt text\" style=\"display: block; margin: 0 auto;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TASK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from scipy.ndimage import rotate, shift\n",
    "\n",
    "# Define functions for each operation\n",
    "\n",
    "def rotation(image, seed):\n",
    "    random.seed(seed)\n",
    "    angle = random.uniform(-25, 25)  # Rotate between -25 and 25 degrees\n",
    "    r_img = rotate(image, angle, reshape=False, mode='reflect')\n",
    "    return r_img\n",
    "\n",
    "def h_flip(image, seed):\n",
    "    random.seed(seed)\n",
    "    if random.random() > 0.5:\n",
    "        hflipped_img = np.fliplr(image)\n",
    "    else:\n",
    "        hflipped_img = image\n",
    "    return hflipped_img\n",
    "\n",
    "def v_flip(image, seed):\n",
    "    random.seed(seed)\n",
    "    if random.random() > 0.5:\n",
    "        vflipped_img = np.flipud(image)\n",
    "    else:\n",
    "        vflipped_img = image\n",
    "    return vflipped_img\n",
    "\n",
    "def v_transl(image, seed):\n",
    "    random.seed(seed)\n",
    "    pixels = random.randint(-30, 30)\n",
    "    shift_vals = [pixels if i == 0 else 0 for i in range(image.ndim)]\n",
    "    return shift(image, shift=shift_vals, mode='reflect')\n",
    "\n",
    "def h_transl(image, seed):\n",
    "    random.seed(seed)\n",
    "    pixels = random.randint(-30, 30)\n",
    "    shift_vals = [pixels if i == 1 else 0 for i in range(image.ndim)]\n",
    "    return shift(image, shift=shift_vals, mode='reflect')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TASK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3485\n",
      "4905\n",
      "3401\n",
      "6171\n",
      "1761\n",
      "6922\n",
      "8584\n",
      "2000\n",
      "7773\n",
      "7881\n",
      "5375\n",
      "1166\n",
      "9116\n",
      "2308\n",
      "599\n",
      "544\n",
      "4579\n",
      "2341\n",
      "7078\n",
      "4240\n",
      "1018\n",
      "6465\n",
      "5525\n",
      "2928\n",
      "5693\n",
      "1329\n",
      "2515\n",
      "3545\n",
      "6925\n",
      "6752\n",
      "9237\n",
      "7365\n",
      "6529\n",
      "2332\n",
      "7274\n",
      "7229\n",
      "4066\n",
      "2022\n",
      "7251\n",
      "7555\n",
      "7677\n",
      "915\n",
      "5187\n",
      "9136\n",
      "4896\n",
      "6013\n",
      "2830\n",
      "6995\n",
      "6695\n",
      "9687\n",
      "1144\n",
      "7886\n",
      "9335\n",
      "6604\n",
      "5185\n",
      "9900\n",
      "8818\n",
      "8868\n",
      "6331\n",
      "9774\n",
      "8462\n",
      "9556\n",
      "4884\n",
      "3500\n",
      "8890\n",
      "9638\n",
      "6059\n",
      "1399\n",
      "4080\n",
      "8142\n",
      "5769\n",
      "2877\n",
      "2730\n",
      "6711\n",
      "3822\n",
      "2151\n",
      "7476\n",
      "5286\n",
      "7735\n",
      "8010\n",
      "1551\n",
      "2474\n",
      "6540\n",
      "1184\n",
      "2757\n",
      "5992\n",
      "2813\n",
      "9807\n",
      "5710\n",
      "8894\n",
      "6223\n",
      "9563\n",
      "8405\n",
      "3878\n",
      "4647\n",
      "7011\n",
      "5829\n",
      "8480\n",
      "8019\n",
      "6153\n",
      "973\n",
      "800\n",
      "9691\n",
      "8017\n",
      "4616\n",
      "1056\n",
      "6055\n",
      "9994\n",
      "6847\n",
      "943\n",
      "3894\n",
      "9806\n",
      "9157\n",
      "4303\n",
      "4711\n",
      "8033\n",
      "8456\n",
      "8811\n",
      "9011\n",
      "6131\n",
      "8051\n",
      "7447\n",
      "6504\n",
      "2144\n",
      "6759\n",
      "3583\n",
      "4275\n",
      "2219\n",
      "3604\n",
      "8650\n",
      "4401\n",
      "2329\n",
      "8119\n",
      "3405\n",
      "3255\n",
      "1982\n",
      "1282\n",
      "3233\n",
      "2173\n",
      "3605\n",
      "5311\n",
      "1068\n",
      "3391\n",
      "6393\n",
      "5307\n",
      "5443\n",
      "3290\n",
      "8085\n",
      "9976\n",
      "19\n",
      "708\n",
      "5727\n",
      "6375\n",
      "5262\n",
      "1166\n",
      "913\n",
      "7823\n",
      "2867\n",
      "3292\n",
      "985\n",
      "3583\n",
      "4275\n",
      "2219\n",
      "3604\n",
      "8650\n",
      "4401\n",
      "2329\n",
      "8119\n",
      "3405\n",
      "3255\n",
      "1982\n",
      "1282\n",
      "3233\n",
      "2173\n",
      "3605\n"
     ]
    }
   ],
   "source": [
    "###Use the functions to implement the augmentation for both images and masks\n",
    "transformations = {\n",
    "    'rot': rotation,\n",
    "    'hflip': h_flip,\n",
    "    'vflip': v_flip,\n",
    "    'vtrans': v_transl,\n",
    "    'htrans': h_transl\n",
    "}\n",
    "tif_imgs = Path(\"../images/tif_images\").glob(\"*.tif\")\n",
    "tif_labels = Path(\"../images/tif_labels\").glob(\"*.tif\")\n",
    "augmented_img_dir = Path(\"../images/\") / \"augmented_images\"\n",
    "augmented_label_dir = Path(\"../images/\") / \"augmented_labels\"\n",
    "augmented_img_dir.mkdir(exist_ok=True)\n",
    "augmented_label_dir.mkdir(exist_ok=True)\n",
    "\n",
    "for img_path, label_path in zip(tif_imgs, tif_labels):\n",
    "    img = np.array(Image.open(img_path))\n",
    "    label = np.array(Image.open(label_path))\n",
    "\n",
    "    for t_name, t_func in transformations.items():\n",
    "        seed = random.randint(0, 10000)  # Same seed for image and mask\n",
    "\n",
    "        aug_img = t_func(img, seed)\n",
    "        aug_msk = t_func(label, seed)\n",
    "\n",
    "        # Save augmented versions\n",
    "        aug_img_pil = Image.fromarray(aug_img.astype(np.uint8))\n",
    "        aug_label_pil = Image.fromarray(aug_msk.astype(np.uint8))\n",
    "        aug_img_pil.save(augmented_img_dir / f\"{t_name}_{img_path.name}\")\n",
    "        aug_label_pil.save(augmented_label_dir / f\"{t_name}_{label_path.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kip-IW6OcQGv-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
